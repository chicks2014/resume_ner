{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tika import parser # pip install tika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Page 1 of 3 \n",
      " \n",
      "\n",
      "Curriculum Vitae \n",
      "\n",
      " \n",
      "\n",
      "Lavajiit Singh        \n",
      "Mobile  : +91-7775859367 \n",
      "Address : Delhi NCR \n",
      "E-Mail  : lavajiit@yandex.com \n",
      "_______________________________________________________________________________________________ \n",
      " \n",
      "\n",
      "PROFESSIONAL SUMMARY \n",
      " Data Science intern with 1+ year of experience comprising Data Science, Data Engineering and Full Stack \n",
      "\n",
      "Development. \n",
      "\n",
      " Built company’s first working ML model that beat baseline accuracy. \n",
      "\n",
      " Improved the data engineering process time by 30% and model’s accuracy by 2% in PySpark. \n",
      "\n",
      " A quick learner and self-motivated individual, who adapts as well as challenges status quo. \n",
      " \n",
      " \n",
      "\n",
      "EXPERIENCE \n",
      " \n",
      "A) Data Science Intern – SIPI-IP, Noida – (4+ months) from September 2018 till date \n",
      "\n",
      " \n",
      "a) Understand the data obtained from research teams and then further conduct comprehensive data cleaning \n",
      "\n",
      "and meticulous EDA. \n",
      "b) Formulate experiments to check the possibility and usability of the data obtained from all teams. \n",
      "c) Regularly interact with research teams to give and receive suggestions and to better understand the \n",
      "\n",
      "business process cycle. \n",
      "d) Beat the baseline accuracy for one team. Currently in the process of doing the same for all teams and \n",
      "\n",
      "improve the accuracy gradually. \n",
      " \n",
      "\n",
      "B) Data Engineering Intern - RedCarpetUp, Delhi – 2 months (from July 2018 till August 2018) \n",
      " \n",
      "\n",
      "e) Carry out ETL process with raw data extraction from csv files, then cleaning it and transforming it for \n",
      "machine learning model (fraud detection model) and loading into PostgreSQL database. Both ETL and ML \n",
      "modelling were done in PySpark’s dataFrame and sparkML libraries respectively. \n",
      "\n",
      "f) Load the data from PostgreSQL and build the machine learning model for fraud detection. \n",
      "g) Actively communicate with fraud review team, KYC team and web developers for continuous refining of \n",
      "\n",
      "whole data science pipeline. \n",
      "\n",
      "h) Increased ML model’s accuracy by 2% and reduced ETL processing time by 30% using Spark’s \n",
      "best practices and regular communication with the teams. \n",
      "\n",
      " \n",
      "C) Full Stack Development Intern - Karmaa Lab, Bangalore – 7 months (from June 2017 till December 2017) \n",
      "\n",
      " \n",
      "a) Built the complete web project from scratch in Django. \n",
      "b) Added the web app for website article summariser using web scraping using BeautifulSoup and NLTK. \n",
      "c) Added geo-fencing capability using google-map APIs in Python and JavaScript. \n",
      "d) Deployed the project on AWS EC2. \n",
      "e) Conducted daily scrums. \n",
      "f) Assisted in new interns’ recruitment. \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "mailto:lavajiit@yandex.com\n",
      "\n",
      "\n",
      "Page 2 of 3 \n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "PROJECTS \n",
      " \n",
      "A) Credit Risk Modelling \n",
      "\n",
      " \n",
      "a) The objective of the project was to predict whether to clear the loan for the new customer or not based on \n",
      "\n",
      "the historical data of 800 customers. Firstly, without looking at the data, noted down the hypothesis i.e. \n",
      "questions on what can increase/decrease the chances of loan getting approved. Using pandas, matplotlib \n",
      "and seaborn, conducted univariate & bivariate data analysis to find out the answers of the questions \n",
      "popped up from the hypothesis. EDA further generated some questions as well as answered the hypothesis. \n",
      "Converted the categorical features into numerical features and then correlation was tested. \n",
      "\n",
      "b) The missing values were imputed and outliers were treated. The skewness was corrected using log \n",
      "transform. \n",
      "\n",
      "c) As it was a classification problem, ML modelling was started with logistic regression with stratified k-fold \n",
      "cross validation. During feature engineering, three new features were derived which represented the data \n",
      "in a better way and improved the model performance. Then Decision Tree and Random Forest and \n",
      "XGBOOST were also tested and random forest turned out to be the most accurate.  \n",
      " \n",
      "\n",
      "B) MNIST Handwritten Digit Recognition \n",
      " \n",
      "\n",
      "a) Dataset contain digits 0-9 with a total of 60,000 training samples and 10,000 test samples. Each sample \n",
      "image is 28x28 and linearized as a vector of size 1x784. So, the training and test datasets are 2-d vectors of \n",
      "size 60000x784 and 10000x784 respectively. \n",
      "\n",
      "b) The modelling was done using ANN using tensorflow. \n",
      "\n",
      "c) Accuracy achieved was 97%. \n",
      " \n",
      "\n",
      "C) Linear Regression and Logistic Regression from scratch \n",
      " \n",
      "\n",
      "The motivation behind these projects was to apply understanding of the algorithms and to use simple dataset \n",
      "for them. The main objective was not to use any machine learning library. The modelling was carried out in the \n",
      "lines of Andrew Ng’s ML course on Coursera and using numpy. Further, it was done using scikit-learn too. \n",
      " \n",
      "\n",
      "D) Belgian Traffic Sign Image Classification \n",
      " \n",
      "The dataset is a collection of 62 different types of traffic signs used on Belgian roads in 62 sub folders in training \n",
      "and test folders. The images are in .ppm format and are read from the subfolders and converted into numpy \n",
      "arrays. Images are labelled as the subfolder names. Feature extraction was needed as they had different sizes. \n",
      "So, images were rescaled to 28x28 and then converted to grayscale. An ANN was built using tensorflow after \n",
      "flattening the input image. Then a fully connected layer of logits was constructed. The model gave the accuracy \n",
      "of 61% which call for further improving the model by adding hidden layers in ANN or using CNN. \n",
      " \n",
      "\n",
      "E) Cats & Dogs Image Classification \n",
      " \n",
      "The problem is similar to Belgian Traffic sign problem. Here we just have 2 classes of images so it’s a binary \n",
      "classification problem. The motivation was to use keras and CNN for modelling. Due to RAM limitation only one \n",
      "epoch was completed which gave accuracy of 71% which gives appositive sign that CNN should have given \n",
      "much better accuracy after completing the set 20 epochs. One interesting finding about keras capability was its \n",
      "intuitive image processing method: ImageDataGenerator which loads the images from the folders and creates \n",
      "training and test set with the functionality of resizing the images, normalizing and assigning classification type \n",
      "on the fly. It makes building the model in few lines. \n",
      "\n",
      "\n",
      "\n",
      "Page 3 of 3 \n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "SKILLS, TOOLS & HANDS-ON \n",
      " \n",
      "\n",
      " Python ( PySpark, Pandas, Numpy, Matplotlib, Scikit-learn, Tensorflow, Keras, Django, Google Map API ) \n",
      "\n",
      " SQL ( MySQL, PostgreSQL ), Hands-on NoSQL ( MongoDB ). \n",
      "\n",
      " Linux, AWS EC2. \n",
      "\n",
      " Quick Learner and always look for problem solving.  \n",
      "\n",
      " Excellent Communication and Organizational skills. \n",
      "\n",
      " \n",
      "\n",
      "WEB LINKS \n",
      " \n",
      "\n",
      "Github       :   https://github.com/lavajiit \n",
      "\n",
      "LinkedIn    :   https://linkedin.com/in/lavajiitsingh \n",
      "\n",
      " \n",
      "\n",
      "MOOC’s \n",
      " \n",
      "\n",
      " Machine Learning by Stanford University - Coursera \n",
      "\n",
      " Machine Learning A-Z™ Hands-On Python & R In Data Science - Udemy \n",
      "\n",
      " Machine Learning Crash Course - Google \n",
      "\n",
      " Spark and Python For Big Bata With PySpark - Udemy \n",
      "\n",
      " Foundations of Data Analysis — Part 1: Statistics Using R - edX \n",
      "\n",
      " Foundations of Data Analysis — Part 1: Inferential Statistics - edX \n",
      "\n",
      " Django 2 & Python, The Ultimate Web Development Bootcamp - Udemy \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "EDUCATION \n",
      " \n",
      "\n",
      "2014-2016 M.Tech, Defence Institute of Advanced Technology (DU), Pune \n",
      "\n",
      "2008-2012 B.Tech, MDU. \n",
      "\n",
      " \n",
      "\n",
      "Reference(s) \n",
      " \n",
      "\n",
      "Available on request. \n",
      "\n",
      " \n",
      "\n",
      "https://github.com/lavajiit\n",
      "https://www.class-central.com/mooc/2244/edx-ut-7-01x-foundations-of-data-analysis\n",
      "https://www.class-central.com/mooc/2244/edx-ut-7-01x-foundations-of-data-analysis\n",
      "https://www.class-central.com/mooc/4804/edx-ut-7-21x-foundations-of-data-analysis-part-2-inferential-statistics\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw = parser.from_file('sample1.pdf')\n",
    "print(raw['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
